{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16df4f86",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b903acad",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9670aa8",
   "metadata": {},
   "source": [
    "The Dataset and DataLoader classes encapsulate the process of pulling your data from storage and exposing it to your training loop in batches.\n",
    "\n",
    "The Dataset is responsible for accessing and processing single instances of data.\n",
    "\n",
    "The DataLoader pulls instances of data from the Dataset (either automatically or with a sampler that you define), collects them in batches, and returns them for consumption by your training loop. The DataLoader works with all kinds of datasets, regardless of the type of data they contain.\n",
    "\n",
    "We use torchvision.transforms.Normalize() to zero-center and normalize the distribution of the image tile content, and download both training and validation data splits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfbb9234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "367214f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shirt Bag Shirt Coat\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img/2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    \n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print(' '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae7255",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9194aa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Pytorch models inherit from torch.nn.Module\n",
    "class GarmentClassifer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifer, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,3)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16, 5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = GarmentClassifer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d677a4",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01202348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3556, 0.9192, 0.7689, 0.9131, 0.2164, 0.2947, 0.2788, 0.5346, 0.4920,\n",
      "         0.3872],\n",
      "        [0.0855, 0.9061, 0.9003, 0.2267, 0.8943, 0.4355, 0.7913, 0.9441, 0.8491,\n",
      "         0.5884],\n",
      "        [0.2734, 0.5215, 0.5082, 0.2961, 0.8016, 0.9316, 0.4068, 0.1876, 0.1776,\n",
      "         0.0364],\n",
      "        [0.0199, 0.6402, 0.3897, 0.2563, 0.4374, 0.7078, 0.4785, 0.4819, 0.7710,\n",
      "         0.9050]])\n",
      "tensor([1, 5, 3, 7])\n",
      "Total Loss for this batch: 2.329662322998047\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# NB: Loss functions expect the data in batches, so we are creating batches of 4\n",
    "# Represents the model's confidence in each of the 10 classes for a given input\n",
    "dummy_outputs = torch.rand(4,10)\n",
    "# Represents the correct class among the 10 being tested\n",
    "dummy_labels = torch.tensor([1,5,3,7])\n",
    "\n",
    "print(dummy_outputs)\n",
    "print(dummy_labels)\n",
    "\n",
    "loss = loss_fn(dummy_outputs, dummy_labels)\n",
    "print('Total Loss for this batch: {}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d98f85b",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "- Learning rate determines the size of the steps the optimizer takes\n",
    "- Momentum nudges the optimizer in the direction of the strongest gradient over multiple steps.\n",
    "- Try some different optimization algorithms such as averaged SGD, Adagrad, Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1464789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d50e983",
   "metadata": {},
   "source": [
    "## The Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221499f0",
   "metadata": {},
   "source": [
    " It enumerates data from the DataLoader, and on each pass of the loop does the following:\n",
    "\n",
    "- Gets a batch of training data from the DataLoader\n",
    "\n",
    "- Zeros the optimizer’s gradients\n",
    "\n",
    "- Performs an inference - that is, gets predictions from the model for an input batch\n",
    "\n",
    "- Calculates the loss for that set of predictions vs. the labels on the dataset\n",
    "\n",
    "- Calculates the backward gradients over the learning weights\n",
    "\n",
    "- Tells the optimizer to perform one learning step - that is, adjust the model’s learning weights based on the observed gradients for this batch, according to the optimization algorithm we chose\n",
    "\n",
    "- It reports on the loss for every 1000 batches.\n",
    "\n",
    "- Finally, it reports the average per-batch loss for the last 1000 batches, for comparison with a validation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dbd7b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "\n",
    "    for i, data in enumerate(training_loader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # compute the loss and it's gradient\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i%1000 == 999:\n",
    "            last_loss = running_loss / 1000     # loss per batch\n",
    "            print(' batch {} loss: {}'.format(i+1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0\n",
    "        \n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a5c039",
   "metadata": {},
   "source": [
    "## Per-Epoch Activity\n",
    "\n",
    "- perform validation by checking our relative loss on a set of data that was not used for training and report this\n",
    "\n",
    "- save a copy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e179a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      " batch 1000 loss: 0.4162347732186172\n",
      " batch 2000 loss: 0.396567293529748\n",
      " batch 3000 loss: 0.38364572353917176\n",
      " batch 4000 loss: 0.3821971240330604\n",
      " batch 5000 loss: 0.4049240105479257\n",
      " batch 6000 loss: 0.37119219710919427\n",
      " batch 7000 loss: 0.3655538364317326\n",
      " batch 8000 loss: 0.36531807727081467\n",
      " batch 9000 loss: 0.3554329101992407\n",
      " batch 10000 loss: 0.36840275773998293\n",
      " batch 11000 loss: 0.385828946279129\n",
      " batch 12000 loss: 0.37769150818089836\n",
      " batch 13000 loss: 0.3770883364690235\n",
      " batch 14000 loss: 0.35604417402122635\n",
      " batch 15000 loss: 0.35870866993500383\n",
      "Loss train 0.35870866993500383 valid 0.3817995488643646\n",
      "EPOCH 2:\n",
      " batch 1000 loss: 0.34877264730090973\n",
      " batch 2000 loss: 0.3457287328160601\n",
      " batch 3000 loss: 0.33760132688374145\n",
      " batch 4000 loss: 0.33484094184680724\n",
      " batch 5000 loss: 0.3353572844403243\n",
      " batch 6000 loss: 0.3454665229913662\n",
      " batch 7000 loss: 0.33355055543732304\n",
      " batch 8000 loss: 0.3310701325015543\n",
      " batch 9000 loss: 0.3336000036658006\n",
      " batch 10000 loss: 0.3241482089545243\n",
      " batch 11000 loss: 0.32699039758832077\n",
      " batch 12000 loss: 0.3300003444870526\n",
      " batch 13000 loss: 0.3400155857603095\n",
      " batch 14000 loss: 0.3024424655645853\n",
      " batch 15000 loss: 0.31948247296665794\n",
      "Loss train 0.31948247296665794 valid 0.34111931920051575\n",
      "EPOCH 3:\n",
      " batch 1000 loss: 0.3292037976515421\n",
      " batch 2000 loss: 0.28610520649628235\n",
      " batch 3000 loss: 0.30275322238792435\n",
      " batch 4000 loss: 0.32031927168099356\n",
      " batch 5000 loss: 0.30374349319332394\n",
      " batch 6000 loss: 0.30313770104594007\n",
      " batch 7000 loss: 0.3114059358359664\n",
      " batch 8000 loss: 0.30976462309969066\n",
      " batch 9000 loss: 0.29982467420765896\n",
      " batch 10000 loss: 0.2767808866605046\n",
      " batch 11000 loss: 0.297013617523422\n",
      " batch 12000 loss: 0.30534218418531234\n",
      " batch 13000 loss: 0.30892568073191795\n",
      " batch 14000 loss: 0.3012230989489617\n",
      " batch 15000 loss: 0.3052959328353172\n",
      "Loss train 0.3052959328353172 valid 0.3353455662727356\n",
      "EPOCH 4:\n",
      " batch 1000 loss: 0.27645557118086433\n",
      " batch 2000 loss: 0.29179115986716353\n",
      " batch 3000 loss: 0.2906918622815647\n",
      " batch 4000 loss: 0.27809312830092675\n",
      " batch 5000 loss: 0.29715052995591756\n",
      " batch 6000 loss: 0.26346558983559454\n",
      " batch 7000 loss: 0.2842287774075485\n",
      " batch 8000 loss: 0.2827711843694915\n",
      " batch 9000 loss: 0.2887893771313356\n",
      " batch 10000 loss: 0.2597854387444604\n",
      " batch 11000 loss: 0.2855141512064729\n",
      " batch 12000 loss: 0.3016743200440651\n",
      " batch 13000 loss: 0.27384553994161254\n",
      " batch 14000 loss: 0.2939058661778399\n",
      " batch 15000 loss: 0.3077876755661564\n",
      "Loss train 0.3077876755661564 valid 0.3284856677055359\n",
      "EPOCH 5:\n",
      " batch 1000 loss: 0.25956817497494195\n",
      " batch 2000 loss: 0.25438268008415615\n",
      " batch 3000 loss: 0.2791623913820222\n",
      " batch 4000 loss: 0.26558581459449854\n",
      " batch 5000 loss: 0.28180749773608793\n",
      " batch 6000 loss: 0.2767702029992652\n",
      " batch 7000 loss: 0.25995115564893057\n",
      " batch 8000 loss: 0.2848827680917129\n",
      " batch 9000 loss: 0.2592140297287406\n",
      " batch 10000 loss: 0.2872932584552036\n",
      " batch 11000 loss: 0.275866165986954\n",
      " batch 12000 loss: 0.26583549927861716\n",
      " batch 13000 loss: 0.26704406929354263\n",
      " batch 14000 loss: 0.2603911641953164\n",
      " batch 15000 loss: 0.267080487483654\n",
      "Loss train 0.267080487483654 valid 0.3122299909591675\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"EPOCH {}:\".format(epoch_number+1))\n",
    "    # Make sure gradient tracking is on and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and \n",
    "    # using population statistics for batch normalization\n",
    "    model.eval()\n",
    "\n",
    "    # Disabling gradient computation and reduce memory consumption\n",
    "    with torch.no_grad():\n",
    "        for i,vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss/(i+1)\n",
    "    print('Loss train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss average per batch for training and validation\n",
    "    writer.add_scalars('Training vs Validation Loss', {'training': avg_loss, 'validation': avg_vloss}, epoch_number+1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b1e760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20123756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
