{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddc94921",
   "metadata": {},
   "source": [
    "# Building Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6814275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Models with Pytorch\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Models with Pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de1bd673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model:\n",
      " TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Just one layer:\n",
      " Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model Params:\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[ 0.0933,  0.0112,  0.0278,  ...,  0.0813,  0.0355, -0.0155],\n",
      "        [-0.0538,  0.0095,  0.0097,  ...,  0.0780, -0.0580, -0.0880],\n",
      "        [ 0.0297, -0.0545, -0.0400,  ..., -0.0958, -0.0323,  0.0478],\n",
      "        ...,\n",
      "        [-0.0847, -0.0996, -0.0570,  ..., -0.0636,  0.0311,  0.0149],\n",
      "        [-0.0492, -0.0312,  0.0997,  ...,  0.0221,  0.0615,  0.0968],\n",
      "        [ 0.0979, -0.0021,  0.0966,  ..., -0.0898,  0.0638, -0.0793]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 4.9517e-02,  6.9481e-03,  6.2736e-02,  6.5808e-02, -1.5988e-02,\n",
      "        -2.6240e-02,  5.5974e-02,  9.1646e-02,  9.4806e-02,  5.9449e-02,\n",
      "        -8.7631e-02, -1.3541e-02, -7.6675e-02,  7.9941e-02, -6.6782e-02,\n",
      "         2.5021e-02,  6.1567e-02, -2.5474e-02, -7.6656e-02, -7.3466e-02,\n",
      "         5.5454e-02, -5.6907e-02, -1.0868e-02, -7.1957e-02,  1.1447e-02,\n",
      "        -6.6164e-02,  8.0546e-03,  1.2810e-02, -8.9311e-02,  4.4084e-02,\n",
      "         9.8887e-02,  8.6429e-02,  9.1484e-02, -4.6559e-03,  5.3302e-02,\n",
      "        -5.0683e-02, -9.4076e-02, -5.0681e-02,  2.3369e-02,  2.2922e-02,\n",
      "        -4.5465e-03, -9.7791e-03,  3.3722e-02, -5.4006e-02, -1.6017e-02,\n",
      "         3.1298e-02,  1.8353e-02,  7.3341e-03, -6.3333e-03,  3.3513e-03,\n",
      "         7.7421e-02,  7.7306e-02,  3.4680e-03,  5.7724e-02, -2.2041e-03,\n",
      "         4.3159e-02,  1.7490e-02, -6.2093e-02, -7.4524e-02, -4.6617e-02,\n",
      "        -6.7671e-02,  1.9427e-02, -8.4657e-02,  4.0639e-02, -2.8901e-02,\n",
      "         4.0137e-03, -9.5713e-02,  9.0927e-02, -1.1618e-02, -5.1880e-02,\n",
      "         7.9364e-02,  1.8215e-02,  2.3260e-02, -1.5966e-02, -1.5340e-03,\n",
      "        -1.1597e-02,  2.7500e-02, -8.2628e-02,  9.4107e-02,  5.2275e-02,\n",
      "         1.8997e-02, -6.5073e-02, -9.6414e-02, -8.5550e-02, -8.5524e-02,\n",
      "         9.8793e-02,  8.1868e-03, -3.5576e-02, -3.7006e-02,  9.9359e-02,\n",
      "        -4.0056e-02, -2.4989e-02,  1.6321e-02,  6.8665e-06, -4.2373e-02,\n",
      "        -9.5506e-02,  9.9154e-02, -8.5816e-02, -6.6931e-02,  1.4503e-02,\n",
      "        -6.9119e-02, -6.8543e-02, -3.4118e-02, -9.6985e-04, -9.5099e-02,\n",
      "        -9.7310e-02,  8.9941e-02, -5.3609e-03, -3.6961e-02, -2.1438e-02,\n",
      "        -2.1896e-02, -5.1542e-02, -1.4897e-02, -8.7742e-02,  7.0313e-02,\n",
      "         6.5849e-02,  5.1587e-02, -7.9382e-02, -9.3881e-02,  2.0887e-02,\n",
      "         1.8360e-02,  6.1203e-02, -9.1190e-02,  6.0922e-02, -1.8350e-02,\n",
      "        -3.4518e-02, -9.8400e-02,  3.1054e-02, -8.4574e-02,  6.7297e-02,\n",
      "        -4.9955e-02, -1.2943e-02, -3.0396e-03, -6.7059e-02, -7.4909e-02,\n",
      "         5.2698e-02, -7.9790e-02,  3.7355e-02,  8.8274e-02,  1.0611e-02,\n",
      "        -6.0558e-02, -1.0161e-02,  9.6115e-02,  5.9934e-02,  9.0652e-02,\n",
      "        -2.2209e-02,  4.2536e-02,  6.4563e-02,  7.5484e-02, -8.7004e-02,\n",
      "         6.9394e-02,  8.0600e-02,  8.7918e-02,  2.5736e-02, -7.2732e-02,\n",
      "         5.5802e-02,  5.1284e-02, -7.4142e-02,  8.0444e-02, -9.6577e-02,\n",
      "        -1.0192e-03, -8.3946e-02,  4.5585e-02, -6.9381e-02, -5.8712e-02,\n",
      "        -1.0259e-03, -1.4334e-02,  3.2942e-02, -9.0507e-02,  4.0074e-02,\n",
      "         3.2885e-04, -3.6589e-02, -7.2506e-02,  4.3355e-02,  8.6847e-02,\n",
      "         5.9775e-02, -1.8840e-02, -3.7714e-02, -3.0142e-02,  9.8935e-02,\n",
      "         4.0955e-02, -2.1368e-03,  6.1106e-02,  7.5349e-02, -6.8436e-02,\n",
      "         7.1404e-02,  2.2240e-02, -3.7150e-02, -7.2534e-02,  9.5592e-02,\n",
      "        -5.1063e-03,  6.2282e-02, -4.0275e-02, -3.2993e-02,  6.4563e-02,\n",
      "        -7.3441e-02, -8.7912e-02, -6.5343e-02, -3.4056e-02, -5.6959e-02],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0471, -0.0017,  0.0309,  ..., -0.0077,  0.0573, -0.0510],\n",
      "        [-0.0461, -0.0513, -0.0542,  ..., -0.0291,  0.0265, -0.0538],\n",
      "        [-0.0194, -0.0129, -0.0022,  ...,  0.0588, -0.0392,  0.0687],\n",
      "        ...,\n",
      "        [-0.0501, -0.0422, -0.0350,  ..., -0.0553, -0.0268,  0.0634],\n",
      "        [-0.0387,  0.0363,  0.0162,  ..., -0.0224, -0.0404,  0.0146],\n",
      "        [ 0.0558,  0.0661, -0.0149,  ..., -0.0080,  0.0453, -0.0105]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0346, -0.0181, -0.0353, -0.0554,  0.0534, -0.0270,  0.0590,  0.0389,\n",
      "        -0.0261,  0.0312], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer Params:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0471, -0.0017,  0.0309,  ..., -0.0077,  0.0573, -0.0510],\n",
      "        [-0.0461, -0.0513, -0.0542,  ..., -0.0291,  0.0265, -0.0538],\n",
      "        [-0.0194, -0.0129, -0.0022,  ...,  0.0588, -0.0392,  0.0687],\n",
      "        ...,\n",
      "        [-0.0501, -0.0422, -0.0350,  ..., -0.0553, -0.0268,  0.0634],\n",
      "        [-0.0387,  0.0363,  0.0162,  ..., -0.0224, -0.0404,  0.0146],\n",
      "        [ 0.0558,  0.0661, -0.0149,  ..., -0.0080,  0.0453, -0.0105]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0346, -0.0181, -0.0353, -0.0554,  0.0534, -0.0270,  0.0590,  0.0389,\n",
      "        -0.0261,  0.0312], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "\n",
    "print('The Model:\\n', tinymodel)\n",
    "\n",
    "print('\\n\\nJust one layer:\\n', tinymodel.linear2)\n",
    "\n",
    "print('\\n\\nModel Params:\\n')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('\\n\\nLayer Params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e6802",
   "metadata": {},
   "source": [
    "This shows the fundamental structure of a PyTorch model: there is an `__init__()` method that defines the layers and other components of a model, and a `forward()` method where the computation gets done. Note that we can print the model, or any of its submodules, to learn about its structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de030a0f",
   "metadata": {},
   "source": [
    "## Linear Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e2203ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[0.1708, 0.4724, 0.6928]])\n",
      "\n",
      "\n",
      "Weight and Bias Parameters:\n",
      "Parameter containing:\n",
      "tensor([[-0.3162, -0.4083,  0.3630],\n",
      "        [ 0.3860,  0.1159, -0.3086]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1978, -0.0044], requires_grad=True)\n",
      "\n",
      "\n",
      "Output:\n",
      "tensor([[ 0.2024, -0.0975]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lin = torch.nn.Linear(3,2)\n",
    "x = torch.rand(1,3)\n",
    "\n",
    "print('Input:')\n",
    "print(x)\n",
    "\n",
    "print('\\n\\nWeight and Bias Parameters:')\n",
    "for param in lin.parameters():\n",
    "    print(param)\n",
    "\n",
    "y = lin(x)\n",
    "print('\\n\\nOutput:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39720b2",
   "metadata": {},
   "source": [
    "## Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8518818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "\n",
    "class LeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1,6,3)\n",
    "        self.conv2 = torch.nn.Conv2d(6,16,3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = torch.nn.Linear(16*6*6, 120)\n",
    "        self.fc2 = torch.nn.Linear(120,84)\n",
    "        self.fc3 = torch.nn.Linear(84,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]     # all dimensions except the batch dimensions\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc22728b",
   "metadata": {},
   "source": [
    "## Recurrent Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bac38fe",
   "metadata": {},
   "source": [
    "Recurrent neural networks (or RNNs) are used for sequential data - anything from time-series measurements from a scientific instrument to natural language sentences to DNA nucleotides. An RNN does this by maintaining a hidden state that acts as a sort of memory for what it has seen in the sequence so far.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46462081",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence),1,-1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465bc8c2",
   "metadata": {},
   "source": [
    "Link for reference: https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0219b8",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8808c6f3",
   "metadata": {},
   "source": [
    "Link: https://pytorch.org/docs/stable/nn.html#transformer-layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46447c86",
   "metadata": {},
   "source": [
    "## Data Manipulation Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a5ee8d",
   "metadata": {},
   "source": [
    "### Maxpooling\n",
    "\n",
    "Max pooling (and its twin, min pooling) reduce a tensor by combining cells, and assigning the maximum value of the input cells to the output cell (we saw this). If you look closely at the values above, you’ll see that each of the values in the maxpooled output is the maximum value of each quadrant of the 6x6 input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35d345f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8154, 0.7255, 0.4330, 0.3691, 0.9561, 0.9617],\n",
      "         [0.4603, 0.1120, 0.2590, 0.0756, 0.9736, 0.0066],\n",
      "         [0.0914, 0.9699, 0.6992, 0.4234, 0.8032, 0.6409],\n",
      "         [0.1872, 0.4598, 0.9655, 0.6025, 0.6152, 0.7163],\n",
      "         [0.2440, 0.2840, 0.2116, 0.5312, 0.6664, 0.0310],\n",
      "         [0.6662, 0.3239, 0.9236, 0.4888, 0.2591, 0.5335]]])\n",
      "tensor([[[0.9699, 0.9736],\n",
      "         [0.9655, 0.7163]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1,6,6)\n",
    "print(my_tensor)\n",
    "\n",
    "maxpool_layer = torch.nn.MaxPool2d(3)\n",
    "print(maxpool_layer(my_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1ec67",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "Normalization layers re-center and normalize the output of one layer before feeding it to another. Centering and scaling the intermediate tensors has a number of beneficial effects, such as letting you use higher learning rates without exploding/vanishing gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eeb1e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[17.4006, 16.6246, 19.8065, 23.2332],\n",
      "         [23.0658, 16.5272, 11.1158, 20.3753],\n",
      "         [11.1270, 20.6154, 24.7695, 12.9475],\n",
      "         [ 8.4940,  5.5755, 13.5272, 24.9915]]])\n",
      "tensor(16.8873)\n",
      "tensor([[[-0.7250, -1.0266,  0.2100,  1.5416],\n",
      "         [ 1.1791, -0.2770, -1.4821,  0.5800],\n",
      "         [-1.1212,  0.5842,  1.3309, -0.7940],\n",
      "         [-0.6282, -1.0223,  0.0513,  1.5992]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor(-2.9802e-08, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1,4,4) * 20 + 5\n",
    "print(my_tensor)\n",
    "\n",
    "print(my_tensor.mean())\n",
    "\n",
    "norm_layer = torch.nn.BatchNorm1d(4)\n",
    "normed_tensor = norm_layer(my_tensor)\n",
    "print(normed_tensor)\n",
    "\n",
    "print(normed_tensor.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f25711c",
   "metadata": {},
   "source": [
    "Link: Batch Normalization | https://arxiv.org/abs/1502.03167"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8630ba56",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "Dropout layers work by randomly setting parts of the input tensor during training - dropout layers are always turned off for inference. This forces the model to learn against this masked or reduced dataset.\n",
    "\n",
    "Below, you can see the effect of dropout on a sample tensor. You can use the optional p argument to set the probability of an individual weight dropping out; if you don’t it defaults to 0.5.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b8ece77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.3705, 0.9996, 1.5912],\n",
      "         [0.7045, 0.3990, 0.8228, 0.9637],\n",
      "         [0.6504, 0.4500, 0.0000, 1.3733],\n",
      "         [0.0000, 0.8640, 0.0000, 0.4564]]])\n",
      "tensor([[[0.9955, 0.3705, 0.9996, 0.0000],\n",
      "         [0.7045, 0.3990, 0.0000, 0.0000],\n",
      "         [0.6504, 0.4500, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4564]]])\n",
      "tensor([[[0.0000, 0.3705, 0.9996, 1.5912],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.4500, 0.0000, 0.0000],\n",
      "         [0.4581, 0.0000, 0.0000, 0.4564]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1,4,4)\n",
    "\n",
    "dropout = torch.nn.Dropout(p=0.4)\n",
    "\n",
    "print(dropout(my_tensor))\n",
    "print(dropout(my_tensor))\n",
    "print(dropout(my_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a81a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
