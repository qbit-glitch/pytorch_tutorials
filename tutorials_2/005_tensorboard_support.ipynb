{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4def8bb",
   "metadata": {},
   "source": [
    "# Tensorboard support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorboard matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3627b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6554c",
   "metadata": {},
   "source": [
    "## Showing images in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb6445",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "# Store separate training nd validation splits in ./data\n",
    "training_set = torchvision.datasets.FashionMNIST('./data',download=True, train=True, transform=transform)\n",
    "\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True, train=False, transform=transform)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_set, batch_size=4, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    validation_set, batch_size=4, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "# Class Labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channels=False):\n",
    "    if one_channels :\n",
    "        img = img.mean(dim=0)\n",
    "    img = img/2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    if one_channels:\n",
    "        plt.imshow(npimg, cmap='Greys')\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "\n",
    "# Extract a batch of 4 images\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a97a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n",
    "\n",
    "writer.add_image('Four Fashion_MNIST Images', img_grid)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aee25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defbbcd1",
   "metadata": {},
   "source": [
    "## Graphing Scalers to Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca41b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b4a721",
   "metadata": {},
   "source": [
    "Now let's train a single epoch and evaluate the training vs validation set losses every 1000 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2f0dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(validation_loader))\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(training_loader, 0):\n",
    "        # basic training loop\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # Every 1000 mini-batches...\n",
    "            print('Batch {}'.format(i + 1))\n",
    "            # Check against the validation set\n",
    "            running_vloss = 0.0\n",
    "\n",
    "            # In evaluation mode some model specific operations can be omitted eg. dropout layer\n",
    "            net.train(False) # Switching to evaluation mode, eg. turning off regularisation\n",
    "            for j, vdata in enumerate(validation_loader, 0):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = net(vinputs)\n",
    "                vloss = criterion(voutputs, vlabels)\n",
    "                running_vloss += vloss.item()\n",
    "            net.train(True) # Switching back to training mode, eg. turning on regularisation\n",
    "\n",
    "            avg_loss = running_loss / 1000\n",
    "            avg_vloss = running_vloss / len(validation_loader)\n",
    "\n",
    "            # Log the running loss averaged per batch\n",
    "            writer.add_scalars('Training vs. Validation Loss',\n",
    "                            { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                            epoch * len(training_loader) + i)\n",
    "\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e85a01",
   "metadata": {},
   "source": [
    "## Visualizing your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8894a5b5",
   "metadata": {},
   "source": [
    "TensorBoard can also be used to examine the data flow within your model. To do this, call the add_graph() method with a model and sample input.\n",
    "\n",
    "When you switch over to TensorBoard, you should see a GRAPHS tab. Double-click the “NET” node to see the layers and data flow within your model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b4026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab a single mini batch\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# add_graph will trace the sample input through your model and render it as a graph\n",
    "writer.add_graph(net, images)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18239da9",
   "metadata": {},
   "source": [
    "## Visualize your Dataset with Embeddings\n",
    "\n",
    "The `add_embedding()` method will project a set of data onto the three dimensions with highest variance, and display them as an interactive 3D chart. The add_embedding() method does this automatically by projecting to the three dimensions with highest variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb9ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random subset of data and corresponding labels\n",
    "def select_n_random(data, labels, n=100):\n",
    "    assert len(data) == len(labels)\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# Extract a random subsets of data\n",
    "images, labels = select_n_random(training_set.data, training_set.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[label] for label in labels]\n",
    "\n",
    "features = images.view(-1, 28*28)\n",
    "writer.add_embedding(features,\n",
    "    metadat=class_labels, label_img=images.unsqueeze(1))\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
