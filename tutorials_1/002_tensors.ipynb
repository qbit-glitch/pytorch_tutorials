{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d2e2137",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "368d7913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensors\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a2db2c",
   "metadata": {},
   "source": [
    "- In Pytorch, we use tensors to encode inputs and outputs of a model as well as the models' paramters\n",
    "\n",
    "- Tensors can run on GPUs or other hardware accelerators. \n",
    "- Tensors are optimized for automatic differentiation.\n",
    "- Tensors and numpy can share the same underlying memory, eliminating the need to copy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9cee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "522fcc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Initializing tensor: directly from data\n",
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b883f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Initializing tensor: From a numpy array\n",
    "n = np.array(data)\n",
    "x_t = torch.from_numpy(n)\n",
    "print(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f31d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[0.3703, 0.4064],\n",
      "        [0.8591, 0.4619]])\n"
     ]
    }
   ],
   "source": [
    "# Initializing Tensor: from another tensor\n",
    "x_ones = torch.ones_like(x_data)    # retains properties of x_data\n",
    "print(x_ones)\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)     # overrides the datatype of x_data\n",
    "print(x_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfede8f",
   "metadata": {},
   "source": [
    "We can use pre-defined tensor dimensions using tuple.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f870e54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9663, 0.2716, 0.9940],\n",
      "        [0.8139, 0.1374, 0.1878]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(rand_tensor)\n",
    "print(ones_tensor)\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2733895a",
   "metadata": {},
   "source": [
    "Tensor attributes describe their shape, datatype and the device on which they are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d727730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 2])\n",
      "Datatype of a tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,2)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of a tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b92fa3a",
   "metadata": {},
   "source": [
    "- 1200 tensor operations including arithmetic, linear algebra, matrix multiplication (transposing, indexing, slicing), sampling and more are present.\n",
    "- By default, tensors are created on the CPU. We need to ecplicitly move tensors to the accelerator using `.to()` method (after checking accelerator availability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddab376e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3005, 0.8623],\n",
      "        [0.2040, 0.1702],\n",
      "        [0.1446, 0.6583]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Move the tensor to the accelerator if it is available\n",
    "if torch.accelerator.is_available():\n",
    "    tensor = tensor.to(torch.accelerator.current_accelerator())\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cfaf1c",
   "metadata": {},
   "source": [
    "Standard Numpy like Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2af21af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First Column: tensor([1., 1., 1., 1.])\n",
      "Last Column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 5., 1., 1.],\n",
      "        [1., 5., 1., 1.],\n",
      "        [1., 5., 1., 1.],\n",
      "        [1., 5., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4,4)\n",
    "\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First Column: {tensor[:,0]}\")\n",
    "print(f\"Last Column: {tensor[...,-1]}\")\n",
    "tensor[:,1] = 5\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e460b64b",
   "metadata": {},
   "source": [
    "- Use `torch.cat` to concatenate a sequence of tensors along a given dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "311825c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 5., 1., 1., 1., 1., 1., 1., 1., 5., 1., 1.],\n",
      "        [1., 5., 1., 1., 5., 5., 5., 5., 1., 5., 1., 1.],\n",
      "        [1., 5., 1., 1., 1., 1., 1., 1., 1., 5., 1., 1.],\n",
      "        [1., 5., 1., 1., 1., 1., 1., 1., 1., 5., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor.T, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bd0301",
   "metadata": {},
   "source": [
    "#### Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c4c4d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[28., 28., 28., 28.],\n",
      "        [28., 28., 28., 28.],\n",
      "        [28., 28., 28., 28.],\n",
      "        [28., 28., 28., 28.]])\n",
      "tensor([[28., 28., 28., 28.],\n",
      "        [28., 28., 28., 28.],\n",
      "        [28., 28., 28., 28.],\n",
      "        [28., 28., 28., 28.]])\n",
      "tensor([[0.3922, 0.2477, 0.0152, 0.7304],\n",
      "        [0.7095, 0.9038, 0.3672, 0.9344],\n",
      "        [0.3671, 0.2024, 0.4035, 0.4287],\n",
      "        [0.8545, 0.7422, 0.7176, 0.7363]])\n",
      "tensor([[28., 28., 28., 28.],\n",
      "        [28., 28., 28., 28.],\n",
      "        [28., 28., 28., 28.],\n",
      "        [28., 28., 28., 28.]])\n",
      "tensor([[ 1.,  5.,  1.,  1.],\n",
      "        [ 5., 25.,  5.,  5.],\n",
      "        [ 1.,  5.,  1.,  1.],\n",
      "        [ 1.,  5.,  1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "y1 = tensor @ tensor.T\n",
    "print(y1)\n",
    "\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "print(y2)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "print(y3)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "print(y3)\n",
    "\n",
    "# Compute element wise product\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor.T, out=z3)\n",
    "print(z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f791e48c",
   "metadata": {},
   "source": [
    "*Single-element tensors*: If you have a one-element tensor, for example by aggregating all values of a tensor into one value, you can convert it to a Python numerical value using `item()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c19e6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010711e1",
   "metadata": {},
   "source": [
    "*Inplace Operations*: Operations that store the result into the operand are called in-place. They are denoted by _ suffix. eg: x.copy_(y), x.t_() will change x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9407c6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [5., 5., 5., 5.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[1., 5., 1., 1.],\n",
      "        [1., 5., 1., 1.],\n",
      "        [1., 5., 1., 1.],\n",
      "        [1., 5., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor)\n",
    "\n",
    "tensor.t_()\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d606710",
   "metadata": {},
   "source": [
    "Note: inplace operations saves some memory, but can be problematic when computing derivatives because of an immediate loss of history. Hence, their use is discouraged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f012bc9",
   "metadata": {},
   "source": [
    "Tensors on the CPU and Numpy arrays can share their underlying memory locations, changing one will change another.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c706998f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(t)\n",
    "\n",
    "n = t.numpy()\n",
    "print(n)\n",
    "\n",
    "t.add_(1)\n",
    "print(t)\n",
    "\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2306fcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[4. 4. 4. 4. 4. 4. 4. 4. 4. 4.]\n",
      "tensor([4., 4., 4., 4., 4., 4., 4., 4., 4., 4.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(10)\n",
    "t = torch.from_numpy(n)\n",
    "print(n)\n",
    "print(t)\n",
    "\n",
    "np.add(n,3, out=n)\n",
    "print(n)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8865a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
